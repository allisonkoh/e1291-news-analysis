{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import os\n",
    "import random\n",
    "random.seed(1984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../newspaper-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (10,11,12,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(data_dir + 'us_news_train.csv')\n",
    "test_df = pd.read_csv(data_dir + 'us_news_test.csv')\n",
    "validation_df = pd.read_csv(data_dir +'us_news_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outlet</th>\n",
       "      <th>outlet_url</th>\n",
       "      <th>datetime</th>\n",
       "      <th>url_orig</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>topic_tags</th>\n",
       "      <th>text</th>\n",
       "      <th>section</th>\n",
       "      <th>news_keywords</th>\n",
       "      <th>subsection</th>\n",
       "      <th>paywall</th>\n",
       "      <th>provider</th>\n",
       "      <th>ideology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnbc</td>\n",
       "      <td>https://www.cnbc.com/</td>\n",
       "      <td>2019-03-15T09:00:46Z</td>\n",
       "      <td>https://www.cnbc.com/2019/03/15/iea-report-ven...</td>\n",
       "      <td>Venezuela's electricity crisis could trigger '...</td>\n",
       "      <td>A nationwide power failure in crisis-stricken ...</td>\n",
       "      <td>Sam Meredith</td>\n",
       "      <td>Oil</td>\n",
       "      <td>WTI Crude (Apr'19), ICE Brent Crude (May'19), ...</td>\n",
       "      <td>A nationwide power failure in crisis-stricken ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Venezuela, oil, electricity, IEA, report, OPEC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnbc</td>\n",
       "      <td>https://www.cnbc.com/</td>\n",
       "      <td>2018-10-01T10:30:36Z</td>\n",
       "      <td>https://www.cnbc.com/2018/10/01/canadas-husky-...</td>\n",
       "      <td>Canada's Husky Energy offers to buy MEG Energy...</td>\n",
       "      <td>Canadian oil and gas producer Husky Energy sai...</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Oil and Gas, Business, Energy, Canada, US: New...</td>\n",
       "      <td>Canadian oil and gas producer Husky Energy sai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Husky Energy, MEG, mergers and acquisitions, M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnbc</td>\n",
       "      <td>https://www.cnbc.com/</td>\n",
       "      <td>2018-08-16T13:15:32Z</td>\n",
       "      <td>https://www.cnbc.com/2018/08/16/travel-apps-to...</td>\n",
       "      <td>3 innovative new travel apps that save time an...</td>\n",
       "      <td>From the cheapest rideshare to 30 percent off ...</td>\n",
       "      <td>Jimmy Im</td>\n",
       "      <td>Make It - Life</td>\n",
       "      <td>Tourism, Travel, Career advice, Entrepreneursh...</td>\n",
       "      <td>Millennials are more likely to increase vacati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>make it, hoteltonight, daily drop, jetlag, tim...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thehill</td>\n",
       "      <td>https://www.thehill.com/</td>\n",
       "      <td>2018-05-03T19:09:42Z</td>\n",
       "      <td>http://thehill.com/homenews/administration/386...</td>\n",
       "      <td>EXCLUSIVE: Giuliani calls for Sessions to 'ste...</td>\n",
       "      <td>“I am waiting for the Attorney General to step...</td>\n",
       "      <td>Niall Stanage</td>\n",
       "      <td>Administration</td>\n",
       "      <td>Russia Investigation, Rudy Giuliani, Michael C...</td>\n",
       "      <td>Rudy Giuliani called for Attorney General Jeff...</td>\n",
       "      <td>Homenews</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbcnews</td>\n",
       "      <td>https://www.bbc.co.uk/news</td>\n",
       "      <td>2018-07-16T14:36:28Z</td>\n",
       "      <td>https://www.bbc.co.uk/sport/golf/44850075</td>\n",
       "      <td>The Open 2018: Tiger Woods with late tee time ...</td>\n",
       "      <td>Tiger Woods receives a tee time of 15:21 BST f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Golf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Three-time champion Tiger Woods has a late sta...</td>\n",
       "      <td>Sport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outlet                  outlet_url              datetime  \\\n",
       "0     cnbc       https://www.cnbc.com/  2019-03-15T09:00:46Z   \n",
       "1     cnbc       https://www.cnbc.com/  2018-10-01T10:30:36Z   \n",
       "2     cnbc       https://www.cnbc.com/  2018-08-16T13:15:32Z   \n",
       "3  thehill    https://www.thehill.com/  2018-05-03T19:09:42Z   \n",
       "4  bbcnews  https://www.bbc.co.uk/news  2018-07-16T14:36:28Z   \n",
       "\n",
       "                                            url_orig  \\\n",
       "0  https://www.cnbc.com/2019/03/15/iea-report-ven...   \n",
       "1  https://www.cnbc.com/2018/10/01/canadas-husky-...   \n",
       "2  https://www.cnbc.com/2018/08/16/travel-apps-to...   \n",
       "3  http://thehill.com/homenews/administration/386...   \n",
       "4          https://www.bbc.co.uk/sport/golf/44850075   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Venezuela's electricity crisis could trigger '...   \n",
       "1  Canada's Husky Energy offers to buy MEG Energy...   \n",
       "2  3 innovative new travel apps that save time an...   \n",
       "3  EXCLUSIVE: Giuliani calls for Sessions to 'ste...   \n",
       "4  The Open 2018: Tiger Woods with late tee time ...   \n",
       "\n",
       "                                         description         author  \\\n",
       "0  A nationwide power failure in crisis-stricken ...   Sam Meredith   \n",
       "1  Canadian oil and gas producer Husky Energy sai...           CNBC   \n",
       "2  From the cheapest rideshare to 30 percent off ...       Jimmy Im   \n",
       "3  “I am waiting for the Attorney General to step...  Niall Stanage   \n",
       "4  Tiger Woods receives a tee time of 15:21 BST f...            NaN   \n",
       "\n",
       "           domain                                         topic_tags  \\\n",
       "0             Oil  WTI Crude (Apr'19), ICE Brent Crude (May'19), ...   \n",
       "1          Energy  Oil and Gas, Business, Energy, Canada, US: New...   \n",
       "2  Make It - Life  Tourism, Travel, Career advice, Entrepreneursh...   \n",
       "3  Administration  Russia Investigation, Rudy Giuliani, Michael C...   \n",
       "4            Golf                                                NaN   \n",
       "\n",
       "                                                text   section  \\\n",
       "0  A nationwide power failure in crisis-stricken ...       NaN   \n",
       "1  Canadian oil and gas producer Husky Energy sai...       NaN   \n",
       "2  Millennials are more likely to increase vacati...       NaN   \n",
       "3  Rudy Giuliani called for Attorney General Jeff...  Homenews   \n",
       "4  Three-time champion Tiger Woods has a late sta...     Sport   \n",
       "\n",
       "                                       news_keywords subsection paywall  \\\n",
       "0  Venezuela, oil, electricity, IEA, report, OPEC...        NaN     NaN   \n",
       "1  Husky Energy, MEG, mergers and acquisitions, M...        NaN     NaN   \n",
       "2  make it, hoteltonight, daily drop, jetlag, tim...        NaN     NaN   \n",
       "3                                                NaN        NaN     NaN   \n",
       "4                                                NaN        NaN     NaN   \n",
       "\n",
       "  provider ideology  \n",
       "0      NaN   center  \n",
       "1      NaN   center  \n",
       "2      NaN   center  \n",
       "3      NaN   center  \n",
       "4      NaN   center  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outlet             object\n",
       "outlet_url         object\n",
       "datetime           object\n",
       "url_orig           object\n",
       "headline           object\n",
       "description        object\n",
       "author             object\n",
       "domain             object\n",
       "topic_tags         object\n",
       "text               object\n",
       "section            object\n",
       "news_keywords      object\n",
       "subsection         object\n",
       "paywall            object\n",
       "provider           object\n",
       "ideology           object\n",
       "ideology_code    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple label encoding of \"ideology\" variable \n",
    "train_df[\"ideology_code\"] = train_df[\"ideology\"].astype('category')\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"ideology_code\"] = train_df[\"ideology_code\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = train_df['headline'].values\n",
    "y = train_df['ideology_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<60000x32280 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 465974 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a decision tree and train\n",
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with 20 trees\n",
    "model = RandomForestClassifier(n_estimators=20,\n",
    "                               bootstrap = True,\n",
    "                               max_features = 'sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual class predictions\n",
    "rf_predictions = model.predict(X_test)\n",
    "# Probabilities for each class\n",
    "rf_probs = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "# Stats about the trees in random forest\n",
    "for ind_tree in model.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of nodes 64468\n",
      "Average maximum depth 2824\n"
     ]
    }
   ],
   "source": [
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training predictions (to demonstrate overfitting)\n",
    "train_rf_predictions = model.predict(X_train)\n",
    "train_rf_probs = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Testing predictions (to determine performance)\n",
    "rf_predictions = model.predict(X_test)\n",
    "rf_probs = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 2], dtype=int8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 4, ..., 3, 0, 4], dtype=int8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2056  640  499  461  363]\n",
      " [ 737 1324  855  605  446]\n",
      " [ 707  924 1482  388  451]\n",
      " [ 532  629  552 1957  410]\n",
      " [ 451  441  412  377 2301]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4586    0.5116    0.4837      4019\n",
      "           1     0.3345    0.3338    0.3341      3967\n",
      "           2     0.3900    0.3750    0.3824      3952\n",
      "           3     0.5166    0.4797    0.4975      4080\n",
      "           4     0.5795    0.5779    0.5786      3982\n",
      "\n",
      "   micro avg     0.4560    0.4560    0.4560     20000\n",
      "   macro avg     0.4558    0.4556    0.4552     20000\n",
      "weighted avg     0.4563    0.4560    0.4557     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,rf_predictions,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-07836847a399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import tools needed for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Pull out one tree from the forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = model.estimators_[5]\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = model.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6072eadd94a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# List of tuples with variable and importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeature_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Sort the feature importances by most important first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfeature_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_importances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(model.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, probs, train_predictions, train_probs):\n",
    "    \"\"\"Compare machine learning model to baseline performance.\n",
    "    Computes statistics and shows ROC curve.\"\"\"\n",
    "    \n",
    "    baseline = {}\n",
    "    \n",
    "    baseline['recall'] = recall_score(y_test, \n",
    "                                     [1 for _ in range(len(y_test))], average=\"macro\")\n",
    "    baseline['precision'] = precision_score(y_test, \n",
    "                                      [1 for _ in range(len(y_test))], average=\"macro\")\n",
    "    baseline['roc'] = 0.5\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    results['recall'] = recall_score(y_test, predictions, average=\"macro\")\n",
    "    results['precision'] = precision_score(y_test, predictions, average=\"macro\")\n",
    "    results['roc'] = roc_auc_score(y_test, probs, average=\"macro\")\n",
    "    \n",
    "    train_results = {}\n",
    "    train_results['recall'] = recall_score(y_train, train_predictions, average=\"macro\")\n",
    "    train_results['precision'] = precision_score(y_train, train_predictions, average=\"macro\")\n",
    "    train_results['roc'] = roc_auc_score(y_train, train_probs, average=\"macro\")\n",
    "    \n",
    "    for metric in ['recall', 'precision', 'roc']:\n",
    "        print(f'{metric.capitalize()} Baseline: {round(baseline[metric], 2)} Test: {round(results[metric], 2)} Train: {round(train_results[metric], 2)}')\n",
    "    \n",
    "    # Calculate false positive rates and true positive rates\n",
    "    base_fpr, base_tpr, _ = roc_curve(y_test, [1 for _ in range(len(test_labels))], average=\"macro\")\n",
    "    model_fpr, model_tpr, _ = roc_curve(y_test, probs, average=\"macro\")\n",
    "\n",
    "    plt.figure(figsize = (8, 6))\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    \n",
    "    # Plot both curves\n",
    "    plt.plot(base_fpr, base_tpr, 'b', label = 'baseline')\n",
    "    plt.plot(model_fpr, model_tpr, 'r', label = 'model')\n",
    "    plt.legend();\n",
    "    plt.xlabel('False Positive Rate'); \n",
    "    plt.ylabel('True Positive Rate'); plt.title('ROC Curves');\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-8497c45415b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rf_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rf_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-594e634d5a7f>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(predictions, probs, train_predictions, train_probs)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'roc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtrain_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    354\u001b[0m     return _average_binary_score(\n\u001b[1;32m    355\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf_predictions, rf_probs, train_rf_predictions, train_rf_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
